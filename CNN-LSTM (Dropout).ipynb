{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQZhGTzXYfGO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MTZ0n04EYo3P"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from string import punctuation\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SsqDwvsnK3p"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time\n",
    "from collections import Counter\n",
    "import re, nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7EjAvXjcGxb"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Hotel_Reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dFtm5mQ4dwnE"
   },
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "1Ky2c91olx16",
    "outputId": "5af023ff-5892-432f-859b-8e5b1425b0d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Data preprocessing\n",
    "## since we found the words are in mixed case letters and with trailing whitespace\n",
    "#we remove those white spaces and converting the reviews to lowercases\n",
    "\n",
    "# convert all positive reviews to lower case, remove trailing whitespace and drop misleading information\n",
    "pos = data.Positive_Review\n",
    "pos = pos.str.lower().str.strip()\n",
    "pos1 = pos[((pos != 'no positive') &\n",
    "           (pos != 'nothing'))]\n",
    "# all punctuation is removed, recover needed info\n",
    "pos1 = pos1.replace({'n t ':' not ', 'dont':'do not'}, regex=True)\n",
    "\n",
    "# convert all negative reviews to lower case, remove trailing whitespace and drop misleading information\n",
    "neg = data.Negative_Review\n",
    "neg = neg.str.lower().str.strip()\n",
    "neg1 = neg[(neg != 'no negative') &\n",
    "      (neg != 'nothing')]\n",
    "# all punctuation is removed, recover needed info\n",
    "neg1 = neg1.replace({'n t ':' not ','dont':'do not'}, regex=True)\n",
    "\n",
    "# # concat positive and negative reviews\n",
    "total_reviews = pd.concat([pos1, neg1], axis=0)\n",
    "\n",
    "\n",
    "# add score to reviews\n",
    "scores = ['positive' for i in range(len(pos1))]\n",
    "scores += ['negative' for i in range(len(neg1))]\n",
    "\n",
    "# one hot encoding (1 for positive, 0 for negative)\n",
    "for i in range(0, len(scores)):\n",
    "    if scores[i] == 'positive':\n",
    "        scores[i] = 1\n",
    "    else:\n",
    "        scores[i] = 0\n",
    "\n",
    "\n",
    "\n",
    "#removing numbers\n",
    "total_reviews = total_reviews.map(lambda x: re.sub('[0-9]','',str(x)))\n",
    "\n",
    "\n",
    "####  remove stopwords\n",
    "\n",
    "# load package\n",
    "\n",
    "import nltk\n",
    "import ssl\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()   #ToktokTokenizer is faster than word_tokenize\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# refine stopwords as we do not want to drop privative\n",
    "# (most reviews are short, dropping them can reverse actual meaning)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "refine_stopword = set(('no', 'nor','not'))\n",
    "new_stopwords = stop_words - refine_stopword\n",
    "\n",
    "\n",
    "text = total_reviews.values\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    cleaned_tokens = [token for token in tokens if token not in new_stopwords]\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "total_reviews = total_reviews.apply(remove_stopwords)\n",
    " \n",
    "# tokenizing\n",
    "total_reviews = total_reviews.apply(tokenizer.tokenize)\n",
    "\n",
    "\n",
    "\n",
    "# create required data frame.\n",
    "review_score = pd.DataFrame()\n",
    "review_score['reviews'] = total_reviews\n",
    "review_score['score'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "zFlQEBR6cUVY",
    "outputId": "6262faf9-4ebb-4a11-bf0c-ecce51137f59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>park outside hotel beautiful</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no real complaints hotel great great location ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>location good staff ok cute hotel breakfast ra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great location nice surroundings bar restauran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazing location building romantic setting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  score\n",
       "0                       park outside hotel beautiful      1\n",
       "1  no real complaints hotel great great location ...      1\n",
       "2  location good staff ok cute hotel breakfast ra...      1\n",
       "3  great location nice surroundings bar restauran...      1\n",
       "4         amazing location building romantic setting      1"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sT_rBumMcgoN"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed=100\n",
    "x=review_score['reviews']\n",
    "y=review_score['score']\n",
    "X_train, X_test,Y_train, Y_test = train_test_split(x,y, test_size=0.3,random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fu-oVOm7MtQk"
   },
   "outputs": [],
   "source": [
    "# Tokenize Text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YS8Nq1b0MwkX",
    "outputId": "d7656665-1dc7-4205-f3c9-3bdeb5f7e79b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Figure size 576x396 with 1 Axes>\n"
     ]
    }
   ],
   "source": [
    "totalNumWords = [len(one_comment) for one_comment in X_train]\n",
    "plt.hist(totalNumWords,bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tt3WODbseGqK"
   },
   "source": [
    "**LSTM Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pIOoPlBLJXD9"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aVIyxbxaL9mV"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 110\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_X1UJU2EBMH"
   },
   "outputs": [],
   "source": [
    "top_words = 100000\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "WuPO3Ex6Nl-z",
    "outputId": "c1347652-e8b2-4231-87ac-6ec44106bed4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 110, 32)           3200000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 3,253,301\n",
      "Trainable params: 3,253,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "-aleZ7bCOKnT",
    "outputId": "14b8e4e1-3218-4565-cd2b-a306cb7e1541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "591306/591306 [==============================] - 2680s 5ms/step - loss: 0.1298 - acc: 0.9534\n",
      "Epoch 2/3\n",
      "591306/591306 [==============================] - 2666s 5ms/step - loss: 0.1188 - acc: 0.9574\n",
      "Epoch 3/3\n",
      "591306/591306 [==============================] - 2663s 5ms/step - loss: 0.1112 - acc: 0.9602\n",
      "Accuracy: 95.29%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=3, batch_size=64)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gKkt6qc68xMX"
   },
   "source": [
    "**LSTM with Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "INXy28Br8fEe"
   },
   "outputs": [],
   "source": [
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gqu4eyvp8krT"
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n995bB2b8oSi"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=3, batch_size=64)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyKG9qmlePVF"
   },
   "source": [
    "**LSTM and Convolutional Neural Network **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "usEhvGz8c46-",
    "outputId": "3c479923-84b6-45a0-e13c-8e37426e37c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# add Conv layer and max pooling layer\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "uhUIMkBadLWh",
    "outputId": "b7afbaff-b784-41ca-de44-e9502526e275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 110, 32)           3200000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 110, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 55, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 55, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 3,256,405\n",
      "Trainable params: 3,256,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "a-X-ln0tdO7z",
    "outputId": "02eb2836-6d1f-4f98-f5ec-81efa6312ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "591306/591306 [==============================] - 1858s 3ms/step - loss: 0.1600 - acc: 0.9416\n",
      "Epoch 2/3\n",
      "591306/591306 [==============================] - 1874s 3ms/step - loss: 0.1338 - acc: 0.9520\n",
      "Epoch 3/3\n",
      "591306/591306 [==============================] - 1910s 3ms/step - loss: 0.1239 - acc: 0.9558\n",
      "Accuracy: 95.18%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=3, batch_size=64)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "“Untitled0.ipynb”的副本",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
